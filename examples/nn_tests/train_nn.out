Train_dl: 4500 Validation_dl: 500
Begin training ...
[TRAIN] Epoch: 1 Loss: 0.10749028405449422 Time: 0:24
[VALID] Epoch: 1 Loss: 0.0660865170927159 Time: 0:4
[TRAIN] Epoch: 2 Loss: 0.05391347782277727 Time: 0:27
[VALID] Epoch: 2 Loss: 0.039316307594638424 Time: 0:4
[TRAIN] Epoch: 3 Loss: 0.04770366719531376 Time: 0:24
[VALID] Epoch: 3 Loss: 0.06509873419328066 Time: 0:4
[TRAIN] Epoch: 4 Loss: 0.045477451123303 Time: 0:26
[VALID] Epoch: 4 Loss: 0.03960020457245998 Time: 0:4
[TRAIN] Epoch: 5 Loss: 0.04543725661705124 Time: 0:28
[VALID] Epoch: 5 Loss: 0.04613288040116999 Time: 0:4
[TRAIN] Epoch: 6 Loss: 0.04552010812094754 Time: 0:26
[VALID] Epoch: 6 Loss: 0.041645502974364534 Time: 0:4
[TRAIN] Epoch: 7 Loss: 0.04459541520051167 Time: 0:27
[VALID] Epoch: 7 Loss: 0.038830565769431925 Time: 0:4
[TRAIN] Epoch: 8 Loss: 0.04449266295078098 Time: 0:26
[VALID] Epoch: 8 Loss: 0.04180643903626083 Time: 0:4
[TRAIN] Epoch: 9 Loss: 0.045982811423143505 Time: 0:27
[VALID] Epoch: 9 Loss: 0.0508058995787272 Time: 0:4
[TRAIN] Epoch: 10 Loss: 0.044091295739313315 Time: 0:27
[VALID] Epoch: 10 Loss: 0.05031070339618828 Time: 0:4
[TRAIN] Epoch: 11 Loss: 0.0429327973834527 Time: 0:26
[VALID] Epoch: 11 Loss: 0.028277563244033268 Time: 0:4
[TRAIN] Epoch: 12 Loss: 0.04460056862940228 Time: 0:28
[VALID] Epoch: 12 Loss: 0.045962603248386184 Time: 0:4
[TRAIN] Epoch: 13 Loss: 0.043124901456853146 Time: 0:27
[VALID] Epoch: 13 Loss: 0.041973939206994576 Time: 0:4
[TRAIN] Epoch: 14 Loss: 0.04071290148224558 Time: 0:38
[VALID] Epoch: 14 Loss: 0.049690372739395 Time: 0:5
[TRAIN] Epoch: 15 Loss: 0.04200926206120773 Time: 0:42
[VALID] Epoch: 15 Loss: 0.04081399469228667 Time: 0:5
[TRAIN] Epoch: 16 Loss: 0.04225629564134874 Time: 0:42
[VALID] Epoch: 16 Loss: 0.03931931618252694 Time: 0:4
[TRAIN] Epoch: 17 Loss: 0.04057924346044829 Time: 0:42
[VALID] Epoch: 17 Loss: 0.03497035610488123 Time: 0:5
[TRAIN] Epoch: 18 Loss: 0.04013951285044945 Time: 0:42
[VALID] Epoch: 18 Loss: 0.07634653732912933 Time: 0:4
[TRAIN] Epoch: 19 Loss: 0.042422746432858933 Time: 0:42
[VALID] Epoch: 19 Loss: 0.030656224329109315 Time: 0:5
[TRAIN] Epoch: 20 Loss: 0.04085253120274119 Time: 0:26
[VALID] Epoch: 20 Loss: 0.036540755899065004 Time: 0:4
[TRAIN] Epoch: 21 Loss: 0.043087485411094625 Time: 0:24
[VALID] Epoch: 21 Loss: 0.04536554110200796 Time: 0:3
[TRAIN] Epoch: 22 Loss: 0.04054890321590372 Time: 0:26
[VALID] Epoch: 22 Loss: 0.03648221429716746 Time: 0:4
Epoch 00022: reducing learning rate of group 0 to 1.0000e-03.
[TRAIN] Epoch: 23 Loss: 0.026193972345701175 Time: 0:28
[VALID] Epoch: 23 Loss: 0.030422164418401686 Time: 0:5
[TRAIN] Epoch: 24 Loss: 0.026121498115771045 Time: 0:44
[VALID] Epoch: 24 Loss: 0.03093838940187228 Time: 0:5
[TRAIN] Epoch: 25 Loss: 0.02613054700102801 Time: 0:44
[VALID] Epoch: 25 Loss: 0.028612227684739276 Time: 0:5
[TRAIN] Epoch: 26 Loss: 0.026108214419070724 Time: 0:42
[VALID] Epoch: 26 Loss: 0.030000527132654827 Time: 0:5
[TRAIN] Epoch: 27 Loss: 0.026161491622418303 Time: 0:43
[VALID] Epoch: 27 Loss: 0.030678655928354955 Time: 0:5
[TRAIN] Epoch: 28 Loss: 0.026267847052672537 Time: 0:43
[VALID] Epoch: 28 Loss: 0.03050373635325562 Time: 0:5
[TRAIN] Epoch: 29 Loss: 0.02621521278923159 Time: 0:33
[VALID] Epoch: 29 Loss: 0.028467505699700423 Time: 0:4
[TRAIN] Epoch: 30 Loss: 0.026177997044533392 Time: 0:26
[VALID] Epoch: 30 Loss: 0.03060003147540313 Time: 0:4
[TRAIN] Epoch: 31 Loss: 0.02612962890619515 Time: 0:27
[VALID] Epoch: 31 Loss: 0.02833499678056823 Time: 0:4
[TRAIN] Epoch: 32 Loss: 0.026178947005798228 Time: 0:27
[VALID] Epoch: 32 Loss: 0.028405319710373602 Time: 0:3
[TRAIN] Epoch: 33 Loss: 0.026214077083570878 Time: 0:27
[VALID] Epoch: 33 Loss: 0.03137792680340294 Time: 0:4
Epoch 00033: reducing learning rate of group 0 to 1.0000e-04.
[TRAIN] Epoch: 34 Loss: 0.02512853518577398 Time: 0:23
[VALID] Epoch: 34 Loss: 0.02692722161188257 Time: 0:4
[TRAIN] Epoch: 35 Loss: 0.025091508270418422 Time: 0:26
[VALID] Epoch: 35 Loss: 0.02691208729798441 Time: 0:4
[TRAIN] Epoch: 36 Loss: 0.02508471448391827 Time: 0:26
[VALID] Epoch: 36 Loss: 0.026915805766695576 Time: 0:3
[TRAIN] Epoch: 37 Loss: 0.02507598771367148 Time: 0:27
[VALID] Epoch: 37 Loss: 0.02694912687006479 Time: 0:4
[TRAIN] Epoch: 38 Loss: 0.025076515916790054 Time: 0:26
[VALID] Epoch: 38 Loss: 0.0269220085803946 Time: 0:4
[TRAIN] Epoch: 39 Loss: 0.025077228792088405 Time: 0:25
[VALID] Epoch: 39 Loss: 0.026931272821869058 Time: 0:3
[TRAIN] Epoch: 40 Loss: 0.02506393194923107 Time: 0:22
[VALID] Epoch: 40 Loss: 0.026914776582429238 Time: 0:4
[TRAIN] Epoch: 41 Loss: 0.025070262801487782 Time: 0:24
[VALID] Epoch: 41 Loss: 0.0269212743320385 Time: 0:4
[TRAIN] Epoch: 42 Loss: 0.02507848352335813 Time: 0:25
[VALID] Epoch: 42 Loss: 0.026928675579181053 Time: 0:3
[TRAIN] Epoch: 43 Loss: 0.025075267882688927 Time: 0:26
[VALID] Epoch: 43 Loss: 0.02692973078944934 Time: 0:4
[TRAIN] Epoch: 44 Loss: 0.025064941591188182 Time: 0:26
[VALID] Epoch: 44 Loss: 0.02694771758912847 Time: 0:4
[TRAIN] Epoch: 45 Loss: 0.02506259816988718 Time: 0:26
[VALID] Epoch: 45 Loss: 0.026958018453951866 Time: 0:3
[TRAIN] Epoch: 46 Loss: 0.025071272440903285 Time: 0:25
[VALID] Epoch: 46 Loss: 0.026965877258079696 Time: 0:3
Epoch 00046: reducing learning rate of group 0 to 1.0000e-05.
[TRAIN] Epoch: 47 Loss: 0.024957736260965868 Time: 0:26
[VALID] Epoch: 47 Loss: 0.027043399285949624 Time: 0:3
[TRAIN] Epoch: 48 Loss: 0.024958074386537518 Time: 0:22
[VALID] Epoch: 48 Loss: 0.02704378307945326 Time: 0:3
[TRAIN] Epoch: 49 Loss: 0.024957532708154054 Time: 0:26
[VALID] Epoch: 49 Loss: 0.02703898401234472 Time: 0:3
[TRAIN] Epoch: 50 Loss: 0.024956589679867847 Time: 0:24
[VALID] Epoch: 50 Loss: 0.02703910303869213 Time: 0:3
[TRAIN] Epoch: 51 Loss: 0.024955854456216894 Time: 0:27
[VALID] Epoch: 51 Loss: 0.027033729009403047 Time: 0:3
[TRAIN] Epoch: 52 Loss: 0.02495478633438137 Time: 0:25
[VALID] Epoch: 52 Loss: 0.02703570128349284 Time: 0:3
[TRAIN] Epoch: 53 Loss: 0.024954394592630807 Time: 0:25
[VALID] Epoch: 53 Loss: 0.027037007008332236 Time: 0:3
[TRAIN] Epoch: 54 Loss: 0.024955188432881557 Time: 0:26
[VALID] Epoch: 54 Loss: 0.027037537485281673 Time: 0:3
[TRAIN] Epoch: 55 Loss: 0.024954319772943157 Time: 0:22
[VALID] Epoch: 55 Loss: 0.027032647621538026 Time: 0:3
[TRAIN] Epoch: 56 Loss: 0.024954576724508508 Time: 0:23
[VALID] Epoch: 56 Loss: 0.027034732130351513 Time: 0:3
[TRAIN] Epoch: 57 Loss: 0.024953019076904007 Time: 0:25
[VALID] Epoch: 57 Loss: 0.027032108200747404 Time: 0:3
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
[TRAIN] Epoch: 58 Loss: 0.02491172060663357 Time: 0:25
[VALID] Epoch: 58 Loss: 0.027064963624522594 Time: 0:3
[TRAIN] Epoch: 59 Loss: 0.02492458631154484 Time: 0:27
[VALID] Epoch: 59 Loss: 0.027087669378151498 Time: 0:3
[TRAIN] Epoch: 60 Loss: 0.02493058201436326 Time: 0:27
[VALID] Epoch: 60 Loss: 0.02709603356473212 Time: 0:4
[TRAIN] Epoch: 61 Loss: 0.024934287918291376 Time: 0:27
[VALID] Epoch: 61 Loss: 0.027101636201834756 Time: 0:4
[TRAIN] Epoch: 62 Loss: 0.024936132622758296 Time: 0:26
[VALID] Epoch: 62 Loss: 0.02710293448619534 Time: 0:3
[TRAIN] Epoch: 63 Loss: 0.02493677627366249 Time: 0:25
[VALID] Epoch: 63 Loss: 0.027103803015911285 Time: 0:3
[TRAIN] Epoch: 64 Loss: 0.024937008708183335 Time: 0:26
[VALID] Epoch: 64 Loss: 0.027103934072666962 Time: 0:3
[TRAIN] Epoch: 65 Loss: 0.02493708980513521 Time: 0:27
[VALID] Epoch: 65 Loss: 0.027104065570469585 Time: 0:3
[TRAIN] Epoch: 66 Loss: 0.02493717113886711 Time: 0:26
[VALID] Epoch: 66 Loss: 0.027104196358842793 Time: 0:4
[TRAIN] Epoch: 67 Loss: 0.024937251655635505 Time: 0:24
[VALID] Epoch: 67 Loss: 0.02710432798515492 Time: 0:4
[TRAIN] Epoch: 68 Loss: 0.024937334003439598 Time: 0:22
[VALID] Epoch: 68 Loss: 0.02710446121393768 Time: 0:4
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
[TRAIN] Epoch: 69 Loss: 0.02493034781961981 Time: 0:25
[VALID] Epoch: 69 Loss: 0.02710515254022747 Time: 0:3
[TRAIN] Epoch: 70 Loss: 0.024930707443968785 Time: 0:25
[VALID] Epoch: 70 Loss: 0.027105854108306553 Time: 0:3
[TRAIN] Epoch: 71 Loss: 0.02493106776074671 Time: 0:27
[VALID] Epoch: 71 Loss: 0.027106551810589775 Time: 0:4
[TRAIN] Epoch: 72 Loss: 0.02493143095859602 Time: 0:24
[VALID] Epoch: 72 Loss: 0.02710724660954588 Time: 0:3
[TRAIN] Epoch: 73 Loss: 0.024931773909162982 Time: 0:24
[VALID] Epoch: 73 Loss: 0.02710790120582424 Time: 0:3
[TRAIN] Epoch: 74 Loss: 0.024932101968157875 Time: 0:25
[VALID] Epoch: 74 Loss: 0.027108463877591655 Time: 0:4
[TRAIN] Epoch: 75 Loss: 0.024932399131284595 Time: 0:25
[VALID] Epoch: 75 Loss: 0.02710902640558159 Time: 0:4
[TRAIN] Epoch: 76 Loss: 0.024932631972198707 Time: 0:26
[VALID] Epoch: 76 Loss: 0.02710937171969855 Time: 0:4
[TRAIN] Epoch: 77 Loss: 0.024932816453673668 Time: 0:27
[VALID] Epoch: 77 Loss: 0.027109722451082282 Time: 0:3
[TRAIN] Epoch: 78 Loss: 0.024933002463696206 Time: 0:26
[VALID] Epoch: 78 Loss: 0.027110064630447673 Time: 0:3
[TRAIN] Epoch: 79 Loss: 0.024933188189181475 Time: 0:24
[VALID] Epoch: 79 Loss: 0.027110420148912382 Time: 0:3
Epoch 00079: reducing learning rate of group 0 to 1.0000e-08.
[TRAIN] Epoch: 80 Loss: 0.0249326318806009 Time: 0:26
[VALID] Epoch: 80 Loss: 0.027110464121895685 Time: 0:4
[TRAIN] Epoch: 81 Loss: 0.024932659691505495 Time: 0:24
[VALID] Epoch: 81 Loss: 0.02711051525002969 Time: 0:4
[TRAIN] Epoch: 82 Loss: 0.024932683711608655 Time: 0:26
[VALID] Epoch: 82 Loss: 0.027110566071910598 Time: 0:3
[TRAIN] Epoch: 83 Loss: 0.024932706580774955 Time: 0:26
[VALID] Epoch: 83 Loss: 0.02711061069703294 Time: 0:4
[TRAIN] Epoch: 84 Loss: 0.02493273133663476 Time: 0:25
[VALID] Epoch: 84 Loss: 0.02711064879642899 Time: 0:4
[TRAIN] Epoch: 85 Loss: 0.02493275548738593 Time: 0:25
[VALID] Epoch: 85 Loss: 0.02711068810993847 Time: 0:3
[TRAIN] Epoch: 86 Loss: 0.02493277907296317 Time: 0:28
[VALID] Epoch: 86 Loss: 0.027110741548319623 Time: 0:3
[TRAIN] Epoch: 87 Loss: 0.024932804028733747 Time: 0:24
[VALID] Epoch: 87 Loss: 0.02711078505558854 Time: 0:4
[TRAIN] Epoch: 88 Loss: 0.024932828173455886 Time: 0:27
[VALID] Epoch: 88 Loss: 0.027110827182210005 Time: 0:4
[TRAIN] Epoch: 89 Loss: 0.024932853009794743 Time: 0:26
[VALID] Epoch: 89 Loss: 0.027110876794168945 Time: 0:3
[TRAIN] Epoch: 90 Loss: 0.024932879679317572 Time: 0:26
[VALID] Epoch: 90 Loss: 0.02711091821955648 Time: 0:3
[TRAIN] Epoch: 91 Loss: 0.024932902698953232 Time: 0:25
[VALID] Epoch: 91 Loss: 0.027110962540488965 Time: 0:4
[TRAIN] Epoch: 92 Loss: 0.024932927253511948 Time: 0:27
[VALID] Epoch: 92 Loss: 0.027111008955992385 Time: 0:3
[TRAIN] Epoch: 93 Loss: 0.024932950991936736 Time: 0:26
[VALID] Epoch: 93 Loss: 0.027111059730613108 Time: 0:4
[TRAIN] Epoch: 94 Loss: 0.02493297486177172 Time: 0:25
[VALID] Epoch: 94 Loss: 0.02711109886318641 Time: 0:3
[TRAIN] Epoch: 95 Loss: 0.024933000352627067 Time: 0:26
[VALID] Epoch: 95 Loss: 0.027111144223291438 Time: 0:3
[TRAIN] Epoch: 96 Loss: 0.02493302473285024 Time: 0:25
[VALID] Epoch: 96 Loss: 0.027111192544481504 Time: 0:4
[TRAIN] Epoch: 97 Loss: 0.024933049067009685 Time: 0:26
[VALID] Epoch: 97 Loss: 0.027111232453216453 Time: 0:3
[TRAIN] Epoch: 98 Loss: 0.024933072136236984 Time: 0:23
[VALID] Epoch: 98 Loss: 0.027111275759290586 Time: 0:3
[TRAIN] Epoch: 99 Loss: 0.02493309528102865 Time: 0:25
[VALID] Epoch: 99 Loss: 0.0271113119361305 Time: 0:4
[TRAIN] Epoch: 100 Loss: 0.024933117524021726 Time: 0:26
[VALID] Epoch: 100 Loss: 0.027111344918249635 Time: 0:3
Finish training !
